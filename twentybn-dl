#!/usr/bin/env python
import os
import os.path as op
import itertools
from urllib.parse import urljoin
from urllib.request import urlretrieve
import concurrent.futures

import requests
from tqdm import tqdm


HTTP_ENDPOINT_BASE = "https://s3-eu-west-1.amazonaws.com/20bn-public-datasets/"
DOWNLOAD_TARGET_BASE = op.expandvars('$HOME/20bn-datasets')
LOWERCASE_ALPHABET = ''.join([chr(i) for i in range(97, 123)])


class MissingChunksException(Exception):
    pass


class Dataset(object):
    """ Dataset on S3 accessible via HTTP. """

    def __init__(self, name, version, last):
        self.name = name
        self.version = version
        self.last = last
        self.tmp_dir = op.join(DOWNLOAD_TARGET_BASE, self.name, 'tmp')
        self.tmp_tgz = op.join(
            self.tmp_dir,
            "20bn-{}-{}.tgz".format(self.name, self.version)
        )
        self.ensure_directories_exist()

    def ensure_directories_exist(self):
        os.makedirs(self.tmp_dir, exist_ok=True)

    def ensure_chunks_exist(self):
        for f in self.filenames:
            chunk_path = op.join(self.tmp_dir, f)
            if not op.isfile(chunk_path):
                message = "Chunk: '{}' is missing!".format(chunk_path)
                raise MissingChunksException(message)

    def filename(self, suffix):
        return "20bn-{}-{}-{}".format(self.name, self.version, suffix)

    @property
    def filenames(self):
        return [self.filename(s) for s in suffix_generator(self.last)]

    def url(self, filename):
        full_path = op.join(self.name, self.version, filename)
        return urljoin(HTTP_ENDPOINT_BASE, full_path)

    @property
    def urls(self):
        return [self.url(f) for f in self.filenames]

    @staticmethod
    def needs_download(url, filepath):
        if not op.exists(filepath):
            return True
        else:
            response = requests.head(url)
            remote_size = response.headers['content-length']
            local_size = op.getsize(filepath)
            if remote_size != local_size:
                return True
            else:
                return False

    def download_chunk(self, url_filename):
        url, filename = url_filename
        filepath = op.join(self.tmp_dir, filename)
        if self.needs_download(url, filepath):
            print("Downloading: '{}'".format(filename))
            urlretrieve(url, filepath)

    def download_chunks(self, max_workers=10):
        with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:
            executor.map(self.download_chunk, zip(self.urls, self.filenames))

    def concat_chunks(self, keep=True, read_chunk_size=65536):
        self.ensure_chunks_exist()
        with open(self.tmp_tgz, 'wb') as target:
            for f in self.filenames:
                chunk_path = op.join(self.tmp_dir, f)
                with open(chunk_path, 'rb') as source:
                    while True:
                        read_bytes = source.read(read_chunk_size)
                        target.write(read_bytes)
                        if len(read_bytes) < read_chunk_size:
                            break


def suffix_generator(last):
    """ Generate filename suffixes.

    Will genrate combination of two letter suffixes, starting at 'aa' and
    finishing at last.

    """
    char_pairs = [''.join(i) for i in
                  itertools.combinations_with_replacement(LOWERCASE_ALPHABET, 2)]
    return list(itertools.takewhile(lambda x: x <= last, char_pairs))


SomethingSomething = Dataset('something-something', 'v1', 'be')
Jester = Dataset('jester', 'v1', 'au')


if __name__ == '__main__':
    print("Will download to: '{}'".format(DOWNLOAD_TARGET_BASE))
    os.makedirs(DOWNLOAD_TARGET_BASE, exist_ok=True)
    print(SomethingSomething.filenames)
    print(SomethingSomething.tmp_tgz)
    SomethingSomething.download_chunks()
    SomethingSomething.ensure_chunks_exist()
