#!/usr/bin/env python
import os
import os.path as op
import itertools
from urllib.parse import urljoin
from urllib.request import urlretrieve
import concurrent.futures
from collections import namedtuple
import pprint

import requests
from tqdm import tqdm


HTTP_ENDPOINT_BASE = "https://s3-eu-west-1.amazonaws.com/20bn-public-datasets/"
DOWNLOAD_TARGET_BASE = op.expandvars('$HOME/20bn-datasets')
LOWERCASE_ALPHABET = ''.join([chr(i) for i in range(97, 123)])

DOWNLOAD_FAILURE = 0
DOWNLOAD_SUCCESS = 1
DOWNLOAD_UNNEEDED = 2
DownloadResult = namedtuple('DownloadResult', ['result', 'filename', 'reason'])



class MissingChunksException(Exception):
    pass

class MissingBigTGZException(Exception):
    pass


class Dataset(object):
    """ Dataset on S3 accessible via HTTP. """

    def __init__(self, name, version, last, count):
        self.name = name
        self.version = version
        self.last = last
        self.count = count
        self.tmp_dir = op.join(DOWNLOAD_TARGET_BASE, 'tmp')
        self.big_tgz = op.join(
            self.tmp_dir,
            "20bn-{}-{}.tgz".format(self.name, self.version)
        )
        self.ensure_directories_exist()

    def ensure_directories_exist(self):
        os.makedirs(self.tmp_dir, exist_ok=True)

    def ensure_chunks_exist(self):
        for f in self.filenames:
            chunk_path = op.join(self.tmp_dir, f)
            if not op.isfile(chunk_path):
                message = "Chunk: '{}' is missing!".format(chunk_path)
                raise MissingChunksException(message)

    def ensure_bigtgz_exists(self):
        if not op.isfile(self.big_tgz):
            m = "Big TGZ: '{}' is missing".format(self.big_tgz)
            raise MissingBigTGZException(m)


    def filename(self, suffix):
        return "20bn-{}-{}-{}".format(self.name, self.version, suffix)

    @property
    def filenames(self):
        return [self.filename(s) for s in suffix_generator(self.last)]

    def url(self, filename):
        full_path = op.join(self.name, self.version, filename)
        return urljoin(HTTP_ENDPOINT_BASE, full_path)

    @property
    def urls(self):
        return [self.url(f) for f in self.filenames]

    @staticmethod
    def needs_download(url, filepath):
        if not op.exists(filepath):
            return True
        else:
            response = requests.head(url)
            remote_size = int(response.headers['Content-Length'])
            local_size = op.getsize(filepath)
            if remote_size > local_size:
                return True
            else:
                return False

    def download_chunk(self, url_filename):
        url, filename = url_filename
        try:
            filepath = op.join(self.tmp_dir, filename)
            needs_dl = self.needs_download(url, filepath)
            if needs_dl:
                print("Downloading: '{}'".format(filename))
                urlretrieve(url, filepath)
                return DownloadResult(DOWNLOAD_SUCCESS, filename, None)
            else:
                print("Not Downloading: '{}'".format(filename))
                return DownloadResult(DOWNLOAD_UNNEEDED, filename, None)
        except Exception as e:
            return DownloadResult(DOWNLOAD_FAILURE, filename, repr(e))

    def download_chunks(self, max_workers=30):
        print('Will now download chunks.')
        with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:
            result = list(executor.map(self.download_chunk, zip(self.urls, self.filenames)))
        DownloadResultProcessor.process_and_print(result)

    def concat_chunks(self, keep=True, read_chunk_size=65536):
        self.ensure_chunks_exist()
        print('Will now concatenate chunks.')
        with open(self.big_tgz, 'wb') as target:
            for f in self.filenames:
                chunk_path = op.join(self.tmp_dir, f)
                with open(chunk_path, 'rb') as source:
                    print("Now appending: '{}'".format(f))
                    while True:
                        read_bytes = source.read(read_chunk_size)
                        target.write(read_bytes)
                        if len(read_bytes) < read_chunk_size:
                            break

    def extract_bigtgz(self):
        self.ensure_bigtgz_exists()

class ExecutorResultProcessor(object):

    def __init__(self,
                 possible_results,
                 failure_index,
                 result_descriptions
                 ):
        assert len(possible_results) == len(result_descriptions)
        self.possible_results = possible_results
        self.failure_index = failure_index
        self.result_descriptions = result_descriptions

    def process_and_print(self, results):
        counts, failures = self.process_results(results)
        self.print_processed_results(counts, failures)
        return len(failures) != 0

    def process_results(self, results):
        counts = {i: 0 for i in self.possible_results}
        failures = []
        for r in results:
            counts[r.result] += 1
            if r.result == self.failure_index:
                failures.append(r)
        return counts, failures

    def print_processed_results(self, counts, failures):
        for p, d in zip(self.possible_results, self.result_descriptions):
            print('{}: {}'.  format(d, counts[p]))
        if failures:
            print('Failures:')
            print(pprint.pformat(failures))


def suffix_generator(last):
    """ Generate filename suffixes.

    Will genrate combination of two letter suffixes, starting at 'aa' and
    finishing at last.

    """
    char_pairs = [''.join(i) for i in
                  itertools.combinations_with_replacement(LOWERCASE_ALPHABET, 2)]
    return list(itertools.takewhile(lambda x: x <= last, char_pairs))


DownloadResultProcessor = ExecutorResultProcessor(
        (DOWNLOAD_FAILURE, DOWNLOAD_SUCCESS, DOWNLOAD_UNNEEDED),
        DOWNLOAD_FAILURE,
        ('Total failures', 'Total downloads', 'Total unneeded'),
)

SomethingSomething = Dataset('something-something', 'v1', 'be', 134636)
Jester = Dataset('jester', 'v1', 'au', 100)


if __name__ == '__main__':
    print("Will download to: '{}'".format(DOWNLOAD_TARGET_BASE))
    os.makedirs(DOWNLOAD_TARGET_BASE, exist_ok=True)
    print(SomethingSomething.filenames)
    print(SomethingSomething.tmp_tgz)
    SomethingSomething.download_chunks()
    SomethingSomething.ensure_chunks_exist()
    SomethingSomething.concat_chunks()
